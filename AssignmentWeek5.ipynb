{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment  week 5  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook made by   (If not filled in correctly: 0 pts for assignment)\n",
    "\n",
    "__Name(s)__: Nora Schinkel & Maarten Boon\n",
    "\n",
    "__Student id(s)__ : 10416730 & 10764399\n",
    "\n",
    "### Pledge (taken from [Coursera's Honor Code](https://www.coursera.org/about/terms/honorcode) )\n",
    "\n",
    "\n",
    "\n",
    "Put here a selfie with your photo where you hold a signed paper with the following text: (if this is team work, put two selfies here, ok). The link must be to some place on the web, not to a local file. **Assignments without the selfies will not be graded and receive 0 points.**\n",
    "\n",
    "> My answers to homework, quizzes and exams will be my own work (except for assignments that explicitly permit collaboration).\n",
    "\n",
    ">I will not make solutions to homework, quizzes or exams available to anyone else. This includes both solutions written by me, as well as any official solutions provided by the course staff.\n",
    "\n",
    ">I will not engage in any other activities that will dishonestly improve my results or dishonestly improve/hurt the results of others.\n",
    "\n",
    "<img src='link to your selfie'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "###  Wordnet (50%, each exercise 10%)\n",
    "\n",
    "* Make Exercises: 5,13,14,26,27 from [WordNet from NLTK](http://www.nltk.org/book/ch02.html#wordnet) NLTK book Chapter 2\n",
    "\n",
    "### DBpedia spotlight (50%)\n",
    "\n",
    "1.  (25%) Create a program (preferably here in this notebook), which can read in a URL, extract the text, run DBPedia spotlight on it, and presents the results in an attractive manner. \n",
    "    * You can use the spotlight API, or run it locally.\n",
    "    * Let the user have some control on the crucial parameters (like confidence, support, etc)\n",
    "    * It should work well on English language text.\n",
    "    * Have some good examples after your code, showing how things work\n",
    "2. (25%) You do a manual evaluation, as is also done in section 4.2 of the spotlight article.\n",
    "    * Manually annotate the following two articles. Indicate the phrases that are named entities, indicate their type, and (if there is any) indicate the wikipedia page in the English Wikipedia which is the best link for that entity.\n",
    "    * Then run DBpedia spotlight on it, and compare the results. Experiment with different settings of the parameters.\n",
    "    * Compute precision and recall for a few different settings, and plot a precison-recall curve (like Figure 3 in the spotlight article). \n",
    "    \n",
    "    * Artciles:\n",
    "        * <http://www.bbc.com/news/world-us-canada-33753067> until \"The deal at a glance\"\n",
    "        * <http://www.bbc.com/news/world-europe-33694773>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My wordnet answers\n",
    "\n",
    "### Q 5\n",
    "Investigate the holonym-meronym relations for some nouns. Remember that there are three kinds of holonym-meronym relation, so you need to use: member_meronyms(), part_meronyms(), substance_meronyms(), member_holonyms(), part_holonyms(), and substance_holonyms()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chair.n.01 \n",
      "\t [] \n",
      "\t [Synset('back.n.08'), Synset('leg.n.03')] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t []\n",
      "professorship.n.01 \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t []\n",
      "president.n.04 \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t []\n",
      "electric_chair.n.01 \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t []\n",
      "chair.n.05 \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t []\n",
      "bath.n.01 \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t []\n",
      "bath.n.02 \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t []\n",
      "bathtub.n.01 \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [Synset('bathroom.n.01')] \n",
      "\t []\n",
      "bath.n.04 \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [Synset('homer.n.03')] \n",
      "\t []\n",
      "bath.n.05 \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [Synset('england.n.01')] \n",
      "\t []\n",
      "bathroom.n.01 \n",
      "\t [] \n",
      "\t [Synset('bathtub.n.01'), Synset('shower_stall.n.01'), Synset('toilet.n.02'), Synset('washbasin.n.02')] \n",
      "\t [] \n",
      "\t [] \n",
      "\t [Synset('dwelling.n.01')] \n",
      "\t []\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "baths = wn.synsets(\"bath\", pos=\"n\")\n",
    "chairs = wn.synsets(\"chair\", pos=\"n\")\n",
    "\n",
    "for synset in chairs:\n",
    "   print( synset.name(), \"\\n\\t\", synset.member_meronyms(), \"\\n\\t\", synset.part_meronyms(), \"\\n\\t\", synset.substance_meronyms(),\"\\n\\t\", synset.member_holonyms(),\"\\n\\t\", synset.part_holonyms(),\"\\n\\t\", synset.substance_holonyms())\n",
    "for synset in baths:\n",
    "   print( synset.name(), \"\\n\\t\", synset.member_meronyms(), \"\\n\\t\", synset.part_meronyms(), \"\\n\\t\", synset.substance_meronyms(),\"\\n\\t\", synset.member_holonyms(),\"\\n\\t\", synset.part_holonyms(),\"\\n\\t\", synset.substance_holonyms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 13 \n",
    "What percentage of noun synsets have no hyponyms? You can get all noun synsets using wn.all_synsets('n')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "nouns = list(wn.all_synsets('n')) #get a list so we can actually get hyponyms\n",
    "from __future__ import division\n",
    "count = len(nouns) #get amount to divide through\n",
    "#print(nouns) #DEBUG\n",
    "nohypo = 0 #clear nohypo\n",
    "for synset in nouns: #for every element of the list\n",
    "    hyps = synset.hyponyms()\n",
    "    if len(hyps) == 0: #always equals 0 for some reason\n",
    "        nohypo += 1   \n",
    "out = nohypo/count * 100 #make output (out = is DEBUG)\n",
    "#print(nohypo) #DEBUG\n",
    "print(out, \"%\") #DEBUG\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 14\n",
    "Define a function supergloss(s) that takes a synset s as its argument and returns a string consisting of the concatenation of the definition of s, and the definitions of all the hypernyms and hyponyms of s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def supergloss(synset):\n",
    "    hyper = ' '.join([hyp.definition() for hyp in synset.hypernyms()])\n",
    "    hypo = ' '.join([hyp.definition() for hyp in synset.hyponyms()])\n",
    "    return (' '.join([synset.definition(), hypo, hyper]))\n",
    "\n",
    "print ((supergloss(wn.synsets(\"oak\")[0])))\n",
    "#' '.join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 26\n",
    "What is the branching factor of the noun hypernym hierarchy? I.e. for every noun synset that has hyponyms — or children in the hypernym hierarchy — how many do they have on average? You can get all noun synsets using wn.all_synsets('n')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get all nouns\n",
    "allSets = list(wn.all_synsets('n'))\n",
    "def countsets(synsets):\n",
    "    numSets = len(synsets)\n",
    "    numHyp = 0\n",
    "    # look for amount of hypernyms and hyponyms and add them to numHyp\n",
    "    for sets in synsets:\n",
    "        hypo = sets.hyponyms()\n",
    "        lenHypo = len(hypo)\n",
    "        hyper = sets.hypernyms()\n",
    "        lenHyper = len(hyper)\n",
    "        branches = lenHypo + lenHyper\n",
    "        numHyp += branches\n",
    "    # average is total branches/total nouns\n",
    "    average = numHyp/numSets\n",
    "    return average\n",
    "\n",
    "print(countsets(allSets))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Q 27\n",
    "The polysemy of a word is the number of senses it has. Using WordNet, we can determine that the noun dog has 7 senses with: len(wn.synsets('dog', 'n')). Compute the average polysemy of nouns, verbs, adjectives and adverbs according to WordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "allNouns = list(wn.all_synsets('n'))\n",
    "allVerbs = list(wn.all_synsets('v'))\n",
    "allAdv = list(wn.all_synsets('r'))\n",
    "allAdj = list(wn.all_synsets('a'))\n",
    "\n",
    "def average_senses(type):\n",
    "    allSense = 0\n",
    "    for set in type:\n",
    "        numSense = len(wn.synsets(set)) #werkt niet :(\n",
    "        allSense += numSense\n",
    "    allType = len(type)\n",
    "    average = allSense/allType\n",
    "    return average\n",
    "\n",
    "print(average_senses(allNouns), \"Average senses nouns\")\n",
    "print(average_senses(allVerbs), \"Average senses verbs\")\n",
    "print(average_senses(allAdv), \"Average senses adverbs\")\n",
    "print(average_senses(allAdj), \"Average senses adjectives\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Spotlight answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US President  as word number  1  in text is annotated to link: \n",
      " http://dbpedia.org/resource/President_of_the_United_States\n",
      "Barack Obama  as word number  14  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Barack_Obama\n",
      "climate change  as word number  121  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Climate_change\n",
      "Clean  as word number  159  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Clean_Air_Act\n",
      "greenhouse gas emissions  as word number  186  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Greenhouse_gas\n",
      "wind  as word number  316  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Wind_power\n",
      "solar power  as word number  325  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Solar_power\n",
      "renewable energy sources  as word number  347  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Renewable_energy\n",
      "Obama  as word number  530  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Barack_Obama\n",
      "climate change  as word number  645  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Climate_change\n",
      "Clean  as word number  674  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Clean_Air_Act\n",
      "CO2 emissions  as word number  716  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Greenhouse_gas\n",
      "pollution  as word number  873  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Pollution\n",
      "climate  as word number  1302  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Climate\n",
      "emission  as word number  1471  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Emissions_trading\n",
      "Environmental Protection Agency  as word number  1542  in text is annotated to link: \n",
      " http://dbpedia.org/resource/United_States_Environmental_Protection_Agency\n",
      "climate change  as word number  1721  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Climate_change\n",
      "president  as word number  1789  in text is annotated to link: \n",
      " http://dbpedia.org/resource/President_of_the_United_States\n",
      "global  as word number  1841  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Global_warming\n",
      "greenhouse gases  as word number  1862  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Greenhouse_gas\n",
      "White House  as word number  2042  in text is annotated to link: \n",
      " http://dbpedia.org/resource/White_House\n",
      "climate  as word number  2120  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Climate\n",
      "president  as word number  2141  in text is annotated to link: \n",
      " http://dbpedia.org/resource/President_of_the_United_States\n",
      "White House  as word number  2213  in text is annotated to link: \n",
      " http://dbpedia.org/resource/White_House\n",
      "Obama  as word number  2229  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Barack_Obama\n",
      "Climate change  as word number  2386  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Climate_change\n",
      "Obama  as word number  2460  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Barack_Obama\n",
      "Clean  as word number  2534  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Clean_Air_Act\n",
      "climate change  as word number  2614  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Climate_change\n",
      "Democratic  as word number  2632  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Democratic_Party_%28United_States%29\n",
      "Obama  as word number  2746  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Barack_Obama\n",
      "Republican  as word number  2785  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Republican_Party_%28United_States%29\n",
      "Republican  as word number  2838  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Republican_Party_%28United_States%29\n",
      "candidate  as word number  2849  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Candidate\n",
      "president  as word number  2863  in text is annotated to link: \n",
      " http://dbpedia.org/resource/President_of_the_United_States\n",
      "Republican  as word number  2961  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Republican_Party_%28United_States%29\n",
      "EPA  as word number  3200  in text is annotated to link: \n",
      " http://dbpedia.org/resource/United_States_Environmental_Protection_Agency\n",
      "greenhouse gas emissions  as word number  3234  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Greenhouse_gas\n",
      "Republican  as word number  3332  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Republican_Party_%28United_States%29\n",
      "climate  as word number  3529  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Climate\n",
      "energy  as word number  3541  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Energy_development\n",
      "president  as word number  3563  in text is annotated to link: \n",
      " http://dbpedia.org/resource/President_of_the_United_States\n",
      "Democrats  as word number  3693  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Democratic_Party_%28United_States%29\n",
      "renewable energy sources  as word number  3814  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Renewable_energy\n",
      "natural gas  as word number  3964  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Natural_gas\n",
      "carbon dioxide  as word number  4000  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Carbon_dioxide\n",
      "natural gas  as word number  4077  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Natural_gas\n",
      "power generation  as word number  4095  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Electricity_generation\n",
      "greenhouse gases  as word number  4171  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Greenhouse_gas\n",
      "environment  as word number  4281  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Environmentalism\n",
      "president  as word number  4331  in text is annotated to link: \n",
      " http://dbpedia.org/resource/President_of_the_United_States\n",
      "White House  as word number  4442  in text is annotated to link: \n",
      " http://dbpedia.org/resource/White_House\n",
      "Republican  as word number  4581  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Republican_Party_%28United_States%29\n",
      "president  as word number  4670  in text is annotated to link: \n",
      " http://dbpedia.org/resource/President_of_the_United_States\n",
      "EPA  as word number  4741  in text is annotated to link: \n",
      " http://dbpedia.org/resource/United_States_Environmental_Protection_Agency\n",
      "carbon emissions  as word number  4757  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Greenhouse_gas\n",
      "Clean Air Act  as word number  4784  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Clean_Air_Act\n",
      "Republican  as word number  4980  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Republican_Party_%28United_States%29\n",
      "president  as word number  5050  in text is annotated to link: \n",
      " http://dbpedia.org/resource/President_of_the_United_States\n",
      "global  as word number  5121  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Global_warming\n",
      "climate change  as word number  5138  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Climate_change\n",
      "climate change  as word number  5370  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Climate_change\n",
      "Clean  as word number  5456  in text is annotated to link: \n",
      " http://dbpedia.org/resource/Clean_Air_Act\n"
     ]
    }
   ],
   "source": [
    "# code for annotating the text in a URL\n",
    "import requests  # http://docs.python-requests.org/en/latest/\n",
    "\n",
    "import json\n",
    "\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "myUrl='http://www.bbc.com/news/world-us-canada-33753067'\n",
    "\n",
    "\n",
    "def annotate(url, confidence, support):\n",
    "    # step 1 get the url and the text out of it\n",
    "    bbc= requests.get(url)\n",
    "    soup= BeautifulSoup(bbc.text) \n",
    "\n",
    "    article=soup.find(\"div\", { \"class\" : \"story-body__inner\" })  # this expression should be imporved to get just the text from the article\n",
    "    article_text= article.text\n",
    "    article_text[:2000]\n",
    "\n",
    "    better_text = re.split(r'\\n{2,}', article_text) #Split in paragraphs\n",
    "    filter_text = ' '.join([paragraphs for paragraphs in better_text if not paragraphs.startswith(' ')]) #remove all indented paragraphs (javascript)\n",
    "\n",
    "    #Step 2: Set up the headers and the body of the request to the spotlight API\n",
    "\n",
    "    spotlight = \"http://spotlight.dbpedia.org/rest/annotate\"\n",
    "    headers = { \"Accept\" : \"application/json\", \"Content-type\" : \"application/x-www-form-urlencoded;charset=utf-8\" }\n",
    "    form= { \"text\" : filter_text, \"confidence\" : confidence, \"support\": support}\n",
    "\n",
    "    #Doe de POST request\n",
    "    ef= requests.post(spotlight, headers=headers,   data=form)\n",
    "\n",
    "    #Pretty parse en print de response van de requestprint(json.dumps(ef.json(), indent=4, separators=( \",\" , \": \"))\n",
    "\n",
    "    basicAn_text = ef.json()\n",
    "    all_annotations = basicAn_text[\"Resources\"]\n",
    "    for annotation in all_annotations:\n",
    "        surface_form = annotation[\"@surfaceForm\"]\n",
    "        offset = annotation[\"@offset\"]\n",
    "        uri = annotation[\"@URI\"]\n",
    "        print(surface_form, \" as word number \", offset, \" in text is annotated to link: \\n\", uri)\n",
    "        \n",
    "     \n",
    "    \n",
    "    #print(all_annotations)    \n",
    "\n",
    "# code for annotating the text in a URL\n",
    "\n",
    "annotate(myUrl, 0.3, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My annotations of the two articles\n",
    "\n",
    "## Links to annotated HTML/PDFs\n",
    "* Use colored markers to indicate which entities you extracted for linking, using color to indicate their type.\n",
    "\n",
    "### Article 1\n",
    "US President Barack Obama has unveiled what he called \"the biggest, most important step we have ever taken\" in tackling climate change.The aim of the revised Clean Power Plan is to cut greenhouse gas emissions from US power stations by nearly a third within 15 years.The measures will place significant emphasis on wind and solar power and other renewable energy sources.However, opponents in the energy industry have vowed to fight the plan.\"I'm convinced no challenge provides a greater threat to the future of the planet,\" Mr Obama said. \"There is such a thing as being too late.\" Image caption The deal at a glanceWhat does it do to combat climate change in the US?The Clean Power Plan sets standards to reduce CO2  emissions by 32% from 2005 levels by 2030, which is 9% more than the proposed rules previously set forth by the Obama administration.How?It sets carbon pollution reduction goals for power plants and requires states to implement plans to meet goals. States have until September 2016 to submit plans, but must comply by 2022. Why are some US states opposed?Coal mining states such as Wyoming, West Virginia and Kentucky fear their economies would suffer and people would be laid off.Is President Obama trying to set an example?The Administration believes the plan will boost a major climate summit in Paris in December and encourage other countries to submit their own plans.For more, read Breaking down the clean power plan Each US state will have an emission-cutting goal assigned to it and must submit a proposal to the Environmental Protection Agency on how it will meet the target.The BBC's Tom Bateman in Washington says President Obama will hope that Monday's announcement secures his legacy on climate change.The measures, our correspondent says, would give the president the moral authority he needs to argue for global reductions in greenhouse gases at a major conference in Paris later this year.However, several state governors are already saying they will simply ignore the plans.In face of the criticism, the White House said the release of the plan was \"the starting gun for an all-out climate push\" by the president and his cabinet.Hillary Clinton vowIn a video released by the White House, Mr Obama said the new limits were backed up by decades of data showing that without action the world faced more extreme weather and escalating health problems.\"Climate change is not a problem for another generation. Not any more,\" Mr Obama said.\"My administration will release the final version of America's Clean Power Plan, the biggest, most important step we have ever taken to combat climate change.\"  Democratic presidential candidate Hillary Clinton said she would defend the plan if she was elected to replace Mr Obama.\"It will need defending. Because Republican doubters and defeatists - including every Republican candidate for president - won't offer any credible solution,\" she said. \"The truth is, they don't want one.\"One Republican presidential candidate, Marco Rubio, said the plan would be \"catastrophic,\" while another, former Florida governor Jeb Bush, said the plan was \"irresponsible and over-reaching\".\"The Supreme Court ruled, it's very clear that the EPA has the authority to regulate greenhouse gas emissions, so regulation is inevitable and I think it's very irresponsible for the Republican leadership to go out there and say we don't have any solutions, this is all wrong, we don't believe in the science, so let's throw up our hands and do nothing,\" Heather Zichal, a former climate and energy adviser to the president and a key architect of the plan told the BBC's Matt McGrath.\"This will be an issue in the 2016 election and because the Democrats have a far more responsible policy position, it will allow them to prevail.\"Correspondents say the emphasis on renewable energy sources marks a significant shift from the earlier version of the plan that sought to speed up a transition from coal-fired power to natural gas plants, which emit less carbon dioxide.It is believed the revised plan will aim to keep the share of natural gas in US power generation at current levels.Power stations are the largest source of greenhouse gases in the US and account for about one third of all such US emissions. Analysis - Matt McGrath, environment correspondentThe big question for the president is how to ensure that these carefully crafted rules don't end up in the recycling bin of history.The White House believes that by vesting the power to implement these changes in the hands of individual states, they are pulling the rug from Republican claims that this is another Washington imposed, big government boondoggle.The president is calculating that the courts will uphold the rights of the EPA to regulate carbon emissions under the Clean Air Act, as they have done on a number of occasions in recent years.He is also gambling that because of the uncertainty of the courts and the long lead time until the regulations bite, many Republican governors will grasp the nettle and accept the changes.The president sees this plan as the cornerstone of his attempt to secure a global treaty on climate change in Paris at the end of the year. But he needs that conference to succeed almost as much as the beleaguered UN process needs him.Getting a deal in the French capital may help \"save the world\" from the worst ravages of climate change. It would also make it very difficult for his successor to unravel the Clean Power Plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url1 = 'http://www.bbc.com/news/world-us-canada-33753067'\n",
    "    \n",
    "def strip_text(url):\n",
    "    bbc= requests.get(url)\n",
    "    soup= BeautifulSoup(bbc.text) \n",
    "\n",
    "    article=soup.find(\"div\", { \"class\" : \"story-body__inner\" })  # this expression should be imporved to get just the text from the article\n",
    "    article_text= article.text\n",
    "    article_text[:2000]\n",
    "\n",
    "    better_text = re.split(r'\\n{2,}', article_text) #Split in paragraphs\n",
    "    filter_text = ' '.join([paragraphs for paragraphs in better_text if not paragraphs.startswith(' ')]) #remove all indented paragraphs (javascript)\n",
    "    return filter_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities and their links\n",
    "* We  use a similar output format as used by Spotlight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code for computing precision and recall and making the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
