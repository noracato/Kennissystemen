{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment  week 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook made by   (If not filled in correctly: 0 pts for assignment)\n",
    "\n",
    "__Name(s)__: Nora Schinkel & Maarten Boon\n",
    "\n",
    "__Student id(s)__ : 10416730 & 10764399\n",
    "\n",
    "### Pledge (taken from [Coursera's Honor Code](https://www.coursera.org/about/terms/honorcode) )\n",
    "\n",
    "\n",
    "\n",
    "Put here a selfie with your photo where you hold a signed paper with the following text: (if this is team work, put two selfies here). The link must be to some place on the web, not to a local file. **Assignments without the selfies will not be graded and receive 0 points.**\n",
    "\n",
    "> My answers to homework, quizzes and exams will be my own work (except for assignments that explicitly permit collaboration).\n",
    "\n",
    ">I will not make solutions to homework, quizzes or exams available to anyone else. This includes both solutions written by me, as well as any official solutions provided by the course staff.\n",
    "\n",
    ">I will not engage in any other activities that will dishonestly improve my results or dishonestly improve/hurt the results of others.\n",
    "\n",
    "<img src='http://i.imgur.com/9g88in2.jpg%5C'/>\n",
    "<img src='https://raw.githubusercontent.com/noracato/Kennissystemen/master/pledge.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infoboxes\n",
    "\n",
    "* We willen voor elke Wikipedia pagina de informatie uit de infobox halen en die gestructureerd opslaan.\n",
    "* In het simpele geval is de infobox een lijst van attribuut-waarde paren:\n",
    "    * het zijn attributen van de \"entiteit\" waar de pagina over gaat.\n",
    "    * Dit zijn dus typisch _RDF subject-predicate-object triples_\n",
    "    * Die je in eerste orde logica als een binaire relatie zou opslaan (bijvoorbeeld _DateOfBirth(Albert-Speer,'19 maart 1905')_)\n",
    "* Je zal zien dat hier flink wat haken en ogen aan zitten.\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "## Inspecteer een voorbeeld\n",
    "\n",
    "* We gaan eens kijken hoe we de attribuut-waarde paren uit de zogenaamde _infoboxen_ uit de Wikipedia paginas kunnen gaan halen.\n",
    "* Vergelijk eens het begin van de file `NLWikipedia/small.xml` met de pagina <https://nl.wikipedia.org/wiki/Albert_Speer>\n",
    "* Die infobox informatie ziet er goed en redelijk eenvoudig te extraheren uit.\n",
    "* Er zijn verschillende _mediawiki_ (het formaat van wikipedia paginas) parsers in omloop. \n",
    "\n",
    "### Je bent niet de eerste met deze opdracht ....\n",
    "\n",
    "* Zoek op het web.\n",
    "* Bijvoorbeeld: <http://stackoverflow.com/questions/8088226/content-of-infobox-of-wikipedia/21107068#21107068>\n",
    "* Zie ook <https://www.mediawiki.org/wiki/Alternative_parsers> voor nog meer mediawiki parsers\n",
    "* Denk ook eens aan <http://pandoc.org/demos.html>\n",
    "* Zie ook [WikipediaInfoBoxes](WikipediaInfoBoxes) is de assignments folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vragen\n",
    "\n",
    "## Download, en extraheer.  (33%)\n",
    "* Download de dump met alle NL wikipedia paginas.\n",
    "\n",
    "\n",
    "1. Verzin een goede datastructuur voor de subject-predicate-object triples die je uit de infoboxes per pagina gaat extraheren.\n",
    "1. Schrijf een functie die uit het text element het infobox deel extraheert, en die lijst attribuut-waarde paren omzet naar jouw datastructuur.\n",
    "2. Pas je functie toe op het [voorbeeld](NLWikipedia/sample.xml, en debug je code.\n",
    "\n",
    "### Nou op de hele file/dump\n",
    "1. Zoek uit hoe je een file stromend kunt inlezen in Python.\n",
    "2. Pas nu je code toe op de hele file. \n",
    "3. Misschien  moet je wel  steeds gegevens naar een file gaan wegschrijven. \n",
    "4. Is jouw gekozen data formaat  handig?\n",
    "\n",
    "#### Hints:\n",
    "* Wil niet meteen alles tegelijk. Als er te veel variatie in de data zit, richt je dan op de meest voorkomende gevallen, en probeer die goed te krijgen. \n",
    "* Probeer wel een beeld te krijgen van \"wat je mist\", en beschrijf dat ook. \n",
    "\n",
    "## Analyseer  (33%)\n",
    "\n",
    "1. Maak statistieken, wat zijn de meest gebruikte attributen, hoe vaak worden ze gebruikt, hoeveel attributen zijn er? Welke waardes worden er veel gebruikt? Hoeveel attributen zie je gemiddeld/mediaan per pagina? \n",
    "2. Doe een analyse op de waardes van de attributen? Kan je bepaalde types vinden?\n",
    "3. Doe een analyse op de uniformiteit van de attribuutnamen. Uit de literatuur blijkt dat er erg veel verschillende manieren worden gebruikt om hetzelfde attribuut weer te geven (bijv, sterfdag, sterfdatum, sterftejaar, etc). Is dat ook zo in jouw dataset? Hoe kom je daar eigenlijk achter? \n",
    " \n",
    " \n",
    "## Reflecteer  (33%)\n",
    "* Je hebt nu flink wat tijd besteed aan wat de mensen achter DBpedia, Yago, FreeBase en meer van dit soort initiatieven ook al doen. De bedoeling van de opdracht was om te ervaren wat een klus het is om een kennisbank te vullen met \"gestructureerde\" informatie van het web. \n",
    "* Beschrijf puntsgewijs wat volgens jullie de lastige onderdelen zijn van dit proces.\n",
    "* Licht er 2-3 uit, en vertel hoe jullie het probleem hebben aangepakt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mijn antwoorden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#dict van dicts, {\"page\":{\"Subject\":_sub_, \"Predicate\":_pred_, \"Obj\":_obj_}}???\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "class RDF(object):\n",
    "    def __init__(self, subject, predicate, obj):\n",
    "        self.s = subject\n",
    "        self.p = predicate\n",
    "        self.o = obj\n",
    "\n",
    "def get_name(infobox):\n",
    "    name = infobox[1]\n",
    "    name = re.split('=', name)[1]\n",
    "    return name\n",
    "\n",
    "url = 'http://maartenmarx.nl/teaching/KennisSystemen/Assignments/NLWikipedia/small.xml'\n",
    "r = requests.get(url) \n",
    "content = r.content\n",
    "content = content.decode('UTF-8')\n",
    "soup = BeautifulSoup(content, 'xml')\n",
    "text = soup.get_text()\n",
    "better_text = re.split(r'\\n', text)\n",
    "better_text = re.split('{{', text)\n",
    "\n",
    "all_triples = []\n",
    "for paragraphs in better_text:\n",
    "    if paragraphs.startswith('Info'):\n",
    "        infobox = re.split('}}', paragraphs)[0]\n",
    "        infobox = re.split(r'\\n', infobox)\n",
    "        subject = get_name(infobox)\n",
    "        infobox.pop(0)\n",
    "        infobox.pop(0)\n",
    "        goodinfo = []\n",
    "        for info in infobox:\n",
    "            if not info.endswith('=') and not info.endswith('= ') and not info == '' and info.startswith('|'):\n",
    "                twoparts = re.split('=', info)\n",
    "                predicate = twoparts[0]\n",
    "                predicate = re.split(' ', predicate)[1]\n",
    "                obj = twoparts[1]\n",
    "                triple = RDF(subject, predicate, obj)\n",
    "                all_triples.append(triple)\n",
    "       \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
