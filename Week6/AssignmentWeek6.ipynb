{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment  week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook made by   (If not filled in correctly: 0 pts for assignment)\n",
    "\n",
    "__Name(s)__: Maarten Boon & Nora Schinkel\n",
    "\n",
    "__Student id(s)__ : 10764399 & 1046730\n",
    "\n",
    "### Pledge (taken from [Coursera's Honor Code](https://www.coursera.org/about/terms/honorcode) )\n",
    "\n",
    "\n",
    "\n",
    "Put here a selfie with your photo where you hold a signed paper with the following text: (if this is team work, put two selfies here). The link must be to some place on the web, not to a local file. **Assignments without the selfies will not be graded and receive 0 points.**\n",
    "\n",
    "> My answers to homework, quizzes and exams will be my own work (except for assignments that explicitly permit collaboration).\n",
    "\n",
    ">I will not make solutions to homework, quizzes or exams available to anyone else. This includes both solutions written by me, as well as any official solutions provided by the course staff.\n",
    "\n",
    ">I will not engage in any other activities that will dishonestly improve my results or dishonestly improve/hurt the results of others.\n",
    "\n",
    "<img src='link to your selfie'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "###  XML Woordenboek lemma (25%)\n",
    "\n",
    "What XML markup would you suggest for the following dictionary extract? Decide a suitable granularity. Thus this extract is the lemma for the word _language_. \n",
    "\n",
    "* HINTS:\n",
    "    * Keep in mind that a dictionary is in a sense a knowledge base with 1000's of these lemmas.\n",
    "    * You thus want uniformity\n",
    "    * Note that this is meant to be read _by humans_. You do not need to store everything that is in this extract.\n",
    "        * some things can be rendered by a stylesheet when a human looks at the extract....\n",
    "\n",
    "```\n",
    "Main Entry: language\n",
    "Pronunciation: ’la[ng]-gwij, -wij\n",
    "Function: noun\n",
    "Etymology: Middle English, from Old French, from langue tongue, language, from Latin\n",
    "lingua - more at TONGUE\n",
    "Date: 14th century\n",
    "1 a : the words, their pronunciation, and the methods of combining them used and understood\n",
    "by a community b (1) : audible, articulate, meaningful sound as produced by the\n",
    "action of the vocal organs (2) : a systematic means of communicating ideas or feelings by\n",
    "the use of conventionalized signs, sounds, gestures, or marks having understood meanings\n",
    "(3) : the suggestion by objects, actions, or conditions of associated ideas or feelings\n",
    "(4) : the means by which animals communicate (5) : a formal system of signs and symbols\n",
    "(as FORTRAN or a calculus in logic) including rules for the formation and transformation\n",
    "of admissible expressions (6) : MACHINE LANGUAGE 1\n",
    "2 a : form or manner of verbal expression; specifically : STYLE b : the vocabulary and\n",
    "phraseology belonging to an art or a department of knowledge c : PROFANITY\n",
    "3 : the study of language especially as a school subject\n",
    "```\n",
    "\n",
    "1. Check that your markup is well-formed. (for instance with the linux command `xmllint`). \n",
    "2. Use `beautifulsoup` to pretty-print your XML.\n",
    "3. Describe why you choose to use attributes and why you choose to use children.\n",
    "\n",
    "\n",
    "### Wikipedia categories (75%)\n",
    " \n",
    "* [Opdracht in notebook](WikipediaCategoriesAssignment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mijn antwoorden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## XML Woordenboek lemma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word language , pronounced as ’la[ng]-gwij, -wij is a noun and was first recorded in 14th century\n",
      "\n",
      " Etymologies:\n",
      "the word lingua  originates from the latin language\n",
      "which transformed into  langue tongue in old french\n",
      "which transformed into  language  in middle english\n",
      "\n",
      " explanation:\n",
      " the words, their pronunciation, and the methods of combining them used and understood by a community \n",
      " audible, articulate, meaningful sound as produced by the action of the vocal organs \n",
      " a systematic means of communicating ideas or feelings by the use of conventionalized signs, sounds, gestures, or marks having understood meanings \n",
      " the suggestion by objects, actions, or conditions of associated ideas or feelings \n",
      "  the means by which animals communicate \n",
      " a formal system of signs and symbols (as FORTRAN or a calculus in logic) including rules for the formation and transformation of admissible expressions \n",
      " MACHINE LANGUAGE 1 \n",
      "\n",
      " explanation:\n",
      " form or manner of verbal expression; specifically : STYLE \n",
      " the vocabulary and phraseology belonging to an art or a department of knowledge \n",
      " POFANITY \n",
      "\n",
      " explanation:\n",
      " the study of language especially as a school subject \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "language_xml = \"\"\"<entry word= \"language\" function= \"noun\" pronounciation= \"’la[ng]-gwij, -wij\" date= \"14th century\">\n",
    "    <etymology>\n",
    "        <tongue language= \"latin\">lingua \n",
    "            <tongue language=\"old french\"> langue tongue\n",
    "                 <tongue language=\"middle english\"> language </tongue>\n",
    "            </tongue>\n",
    "        </tongue>\n",
    "    </etymology>\n",
    "    <meanings>\n",
    "        <meaning> \n",
    "            <submeaning> the words, their pronunciation, and the methods of combining them used and understood by a community </submeaning>\n",
    "            <submeaning>\n",
    "                <subsubmeaning> audible, articulate, meaningful sound as produced by the action of the vocal organs </subsubmeaning>\n",
    "                <subsubmeaning> a systematic means of communicating ideas or feelings by the use of conventionalized signs, sounds, gestures, or marks having understood meanings </subsubmeaning>\n",
    "                <subsubmeaning> the suggestion by objects, actions, or conditions of associated ideas or feelings </subsubmeaning>\n",
    "                <subsubmeaning>  the means by which animals communicate </subsubmeaning>\n",
    "                <subsubmeaning> a formal system of signs and symbols (as <ref>FORTRAN</ref> or a calculus in logic) including rules for the formation and transformation of admissible expressions </subsubmeaning>\n",
    "                <subsubmeaning> <ref>MACHINE LANGUAGE 1</ref> </subsubmeaning>\n",
    "            </submeaning>\n",
    "        </meaning>\n",
    "        <meaning>\n",
    "            <submeaning> form or manner of verbal expression; specifically : <ref>STYLE</ref> </submeaning>\n",
    "            <submeaning> the vocabulary and phraseology belonging to an art or a department of knowledge </submeaning>\n",
    "            <submeaning> <ref>POFANITY</ref> </submeaning>\n",
    "        </meaning>\n",
    "        <meaning> the study of language especially as a school subject </meaning>\n",
    "    </meanings>            \n",
    "</entry>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(language_xml, \"xml\")\n",
    "attrib_entry = soup.find('entry').attrs #extract things from entry and pretty print it\n",
    "word = attrib_entry['word']\n",
    "pronounc = attrib_entry['pronounciation']\n",
    "date = attrib_entry['date']\n",
    "function = attrib_entry['function']\n",
    "print(\"The word\", word, \", pronounced as\", pronounc ,\"is a\", function, \"and was first recorded in\", date)\n",
    "\n",
    "tongues = soup.find_all('tongue') #pretty print etymology\n",
    "etyms = []\n",
    "print(\"\\n Etymologies:\")\n",
    "for tongue in tongues:\n",
    "    language = tongue['language']\n",
    "    tongue_text = tongue.get_text()\n",
    "    better_text = re.split(r'\\n', tongue_text) #Split in words\n",
    "    etym = better_text[0]\n",
    "    etyms.append([language,etym])\n",
    "\n",
    "tongue = etyms[0] #first tongue\n",
    "language = tongue[0]\n",
    "word = tongue[1]\n",
    "del etyms[0]\n",
    "print(\"the word\", word, \"originates from the\", language, \"language\")\n",
    "for etym in etyms: #loop for pretty print of rest of tongue\n",
    "    tongue = etym\n",
    "    language = tongue[0]\n",
    "    word = tongue[1]\n",
    "    print(\"which transformed into\", word, \"in\", language)\n",
    "\n",
    "meanings = soup.find_all('meaning') #pretty print meanings\n",
    "for meaning in meanings:\n",
    "    print(\"\\n explanation:\")\n",
    "    meaning_text = meaning.get_text()\n",
    "    submeanings = re.split(r'\\n',meaning_text)\n",
    "    filtertext = [lines for lines in submeanings if lines] #remove all empty line\n",
    "    for text in filtertext:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mijn Wikipedia categorie antwoorden\n",
    "\n",
    "* Geef duidelijk in een MarkDown cell aan welke vraag je beantwoord.\n",
    "* Eventuele ode komt dan daarna in executeerbare cellen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download en representeer\n",
    "Onze representatie is een lijst met DAGnode elementen uit de zelfgemaakte class DAGnode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import ast\n",
    "\n",
    "# defining the DAG structure, containing its own term and its children\n",
    "class DAGnode(object):\n",
    "    def __init__(self, term):\n",
    "        self.children = []\n",
    "        self.parents = []\n",
    "        self.term = term\n",
    "        \n",
    "# function to add a term and its children to a list via an url from the recommended API     \n",
    "def add_term(url, node_list):\n",
    "    #get the json string from the page\n",
    "    content = url.content\n",
    "    #make the string into a dict\n",
    "    content = content.decode('UTF-8')\n",
    "    content = ast.literal_eval(content)\n",
    "    #get all categorys from the dict\n",
    "    cats = content['query']['categorymembers']\n",
    "    if len(cats) != 0:\n",
    "        #instantiate head and the node list\n",
    "        headterm = cats[0]['title']\n",
    "        #get rid of things like 'portal:' or 'categroie:'\n",
    "        headterm = headterm.split(\":\")\n",
    "        if len(headterm) == 2:\n",
    "            headterm = headterm[1]\n",
    "        else: \n",
    "            headterm = headterm[0]\n",
    "\n",
    "\n",
    "\n",
    "        already_there = 0\n",
    "        #check if headnode is already present in node_list, if it is, modify that one\n",
    "        for node in node_list:\n",
    "            if node.term == headterm:\n",
    "                #add all kids\n",
    "                for cat in cats:\n",
    "                    new_kid_term = cat['title']\n",
    "\n",
    "                     #get rid of things like 'portal:' or 'categroie:'\n",
    "                    new_kid_term = new_kid_term.split(\":\")\n",
    "                    if len(new_kid_term) == 2:\n",
    "                        new_kid_term = new_kid_term[1]\n",
    "                    else: \n",
    "                        new_kid_term = new_kid_term[0]\n",
    "\n",
    "                    kid_there = 0\n",
    "                    #head is present in cat list, do not add as a child of itself\n",
    "                    if node.term != new_kid_term:\n",
    "                        #add child to head\n",
    "                        node.children.append(new_kid_term)\n",
    "\n",
    "                        #check if kid is not already present in node_list, when its not, append it\n",
    "                        for subnode in node_list:\n",
    "                            if subnode.term == new_kid_term:\n",
    "                                subnode.parents.append(headterm)\n",
    "                                kid_there = 1\n",
    "                        if kid_there == 0:\n",
    "                            new_kid = DAGnode(new_kid_term)\n",
    "                            new_kid.parents.append(headterm)\n",
    "                            node_list.append(new_kid)\n",
    "                already_there = 1\n",
    "\n",
    "        # if headnode is not present in list, create one and append it\n",
    "        if already_there == 0:\n",
    "            head = DAGnode(headterm)\n",
    "            #add all kids\n",
    "            for cat in cats:\n",
    "                new_kid_term = cat['title']\n",
    "\n",
    "                #get rid of things like 'portal:' or 'categroie:'\n",
    "                new_kid_term = new_kid_term.split(\":\")\n",
    "                if len(new_kid_term) == 2:\n",
    "                    new_kid_term = new_kid_term[1]\n",
    "                else: \n",
    "                    new_kid_term = new_kid_term[0]\n",
    "\n",
    "                kid_there = 0\n",
    "                #head is present in cat list, do not add as a child of itself\n",
    "                if head.term != new_kid_term:\n",
    "                    head.children.append(new_kid_term)\n",
    "                    #check if kid is not already present in node_list, when its not, append it\n",
    "                    for subnode in node_list:\n",
    "                        if subnode.term == new_kid_term:\n",
    "                            subnode.parents.append(headterm)\n",
    "                            kid_there = 1\n",
    "                    if kid_there == 0:\n",
    "                        new_kid = DAGnode(new_kid_term)\n",
    "                        new_kid.parents.append(headterm)\n",
    "                        node_list.append(new_kid)\n",
    "            #add head to node_list\n",
    "            node_list.append(head)\n",
    "    return(node_list)\n",
    "\n",
    "\n",
    "\n",
    "# Hoera het werkt! We halen alle subcategorieen van Alle op via deze url.\n",
    "# Wanneer we deze twee keer toevoegen aan de lijst, wordt niks dubbel, alleen heel veel kinderen.\n",
    "# Dit is handig wanneer verschillende parents hetzelfde kind hebben\n",
    "# Heel veel kinderen maakt niets uit want elke hoofdterm gaat maar eenmaal geparst worden. \n",
    "\n",
    "alle = requests.get('https://nl.wikipedia.org/w/api.php?action=query&list=categorymembers&cmtitle=Category:Alles&format=json')\n",
    "\n",
    "list1 = add_term(alle, [])\n",
    "#for obj in list1:\n",
    "  #  print(obj.term, \"\\t\", obj.children)\n",
    "    \n",
    "cultuur = requests.get('https://nl.wikipedia.org/w/api.php?action=query&list=categorymembers&cmtitle=Category:Cultuur&format=json')\n",
    "list2 = add_term(cultuur, list1)\n",
    "gesch = requests.get('https://nl.wikipedia.org/w/api.php?action=query&list=categorymembers&cmtitle=Category:Geschiedenis&format=json')\n",
    "list2 = add_term(gesch, list2)\n",
    "weten = requests.get('https://nl.wikipedia.org/w/api.php?action=query&list=categorymembers&cmtitle=Category:Wetenschep&format=json')\n",
    "list2 = add_term(weten, list2)\n",
    "techniek = requests.get('https://nl.wikipedia.org/w/api.php?action=query&list=categorymembers&cmtitle=Category:Techniek&format=json')\n",
    "list2 = add_term(techniek, list2)\n",
    "buigen = requests.get('https://nl.wikipedia.org/w/api.php?action=query&list=categorymembers&cmtitle=Category:Buigen&format=json')\n",
    "list2 = add_term(buigen, list2)\n",
    "besch = requests.get('https://nl.wikipedia.org/w/api.php?action=query&list=categorymembers&cmtitle=Category:Beschaving&format=json')\n",
    "list2 = add_term(besch, list2)\n",
    "print(\"\\n\")\n",
    "\n",
    "for obj in list2:\n",
    "    print(obj.term, \"\\t\", obj.children, \"\\t\", obj.parents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyseer\n",
    "Al hebben we niet alle categorieen kunnen ophalen, als deze er wel allemaal zouden zijn zouden onderstaande functies nog steeds werken.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"totaal categorieen is :, 36, \\n de diepste diepte is, 2, \\n degene met de meeste kinderen is, [9, 'Cultuur'], \\n degene met de meeste nakomelingen is, [35, 'Hoofdpagina']\""
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyse(nlist):\n",
    "    total_cat = len(nlist)\n",
    "    depth = get_depth(nlist)\n",
    "    kids = []\n",
    "    parents = []\n",
    "    grands = []\n",
    "    most_kids = 0\n",
    "    node_most_kids = \"\"\n",
    "    most_grakids = 0\n",
    "    node_most_grakids = \"\"\n",
    "    for node in nlist:\n",
    "        # tel aantal kinderen, ouders etc.\n",
    "        count_kids = len(node.children)\n",
    "        kids.append(count_kids)\n",
    "        count_parents = len(node.parents)\n",
    "        parents.append(count_parents)\n",
    "        count_grands = len(get_grandparents(node, nlist, []))\n",
    "        grands.append(count_grands)\n",
    "        #who has most kids\n",
    "        if count_kids > most_kids:\n",
    "            most_kids = count_kids\n",
    "            node_most_kids = node.term\n",
    "        # who has most nakomelingen\n",
    "        count_grakid = len(get_grandkids(node, nlist, []))\n",
    "        if count_grakid > most_grakids:\n",
    "            most_grakids = count_grakid\n",
    "            node_most_grakids = node.term\n",
    "    #plot alles\n",
    "    count_same(parents, 'bo')\n",
    "    count_same(kids,'ro')\n",
    "    count_same(grands, 'yo')\n",
    "    plt.show()\n",
    "    return [\"totaal categorieen is :\", total_cat,\"\\n de diepste diepte is\", depth,\"\\n degene met de meeste kinderen is\", [most_kids, node_most_kids],\"\\n degene met de meeste nakomelingen is\",[most_grakids, node_most_grakids] ]\n",
    "    \n",
    "    \n",
    "def count_same(nlist, color):\n",
    "    x =[]\n",
    "    y =[]\n",
    "    done = 0\n",
    "    for elem in nlist:\n",
    "        for counted in x:\n",
    "            if counted == elem:\n",
    "                done = 1\n",
    "        if done == 0:\n",
    "            number = nlist.count(elem)\n",
    "            x.append(elem)\n",
    "            y.append(number)\n",
    "        done = 0\n",
    "    plt.plot(x,y,color)\n",
    "    \n",
    "        \n",
    "def get_grandparents(node, nlist, grandparents):\n",
    "    anc = node.parents\n",
    "    if anc != []:\n",
    "        for parent in anc:\n",
    "            for parentnode in nlist:\n",
    "                if parentnode.term == parent:\n",
    "                    grandparents.append(parentnode)\n",
    "                    get_grandparents(parentnode, nlist, grandparents)\n",
    "    return grandparents\n",
    "    \n",
    "def get_grandkids(node, nlist, grandkids):\n",
    "    kids = node.children\n",
    "    if kids != []:\n",
    "        for kid in kids:\n",
    "            for kidnode in nlist:\n",
    "                if kidnode.term == kid:\n",
    "                    grandkids.append(kidnode)\n",
    "                    get_grandkids(kidnode, nlist, grandkids)\n",
    "    return grandkids\n",
    "    \n",
    "    \n",
    "def get_depth(nlist):\n",
    "    for node in nlist:\n",
    "        #find headnode\n",
    "        if node.children == []:\n",
    "            for parent in node.parents:\n",
    "                depth = 1\n",
    "                depth = depth_calc(parent, nlist, depth)\n",
    "    return depth\n",
    "\n",
    "def depth_calc(node, nlist, depth):\n",
    "    for nodes in nlist:\n",
    "        if nodes.term == node:\n",
    "            parents = nodes.parents\n",
    "            if parents != []:\n",
    "                for parent in parents:\n",
    "                    depth +=1\n",
    "                    depth_calc(parent, nlist, depth)\n",
    "    return depth\n",
    "                \n",
    "', '.join(map(str, analyse(list2)))           \n",
    "#str(analyse(list2)).strip('[]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflectie\n",
    "Wat wij lastig vonden aan deze opdracht:\n",
    "* Het ophalen van wikipedia: na 1,5 uur zoeken naar het juiste dump bestand op internet zijn we toch maar de API gaan gebruiken.\n",
    "* Het implementeren van de datastructuur kostte veel meer tijd dan het analyseren van de structuur. Omdat voor alles 30% stond, hebben wij daar ons aardig op verkeken en zijn niet toegekomen aan het laatste onderdeel.\n",
    "* De ziekte van Maarten in het weekend\n",
    "* Het ophalen via de API: soms, wanneer je bijvoorbeeld Heelal op deze manier opvraagt, geeft de json dump niet heelal zelf als categorie mee. Dit is erg onhandig aangezien bij 3/4 van de gevallen de eigen categorie zelf werd meegegeven. Hier kwam ik helaas pas laat achter en is er niets meer aan kunne doen.\n",
    "Technieken:\n",
    "* Het implementeren van de klasse was erg leuk om te doen, omdat ik dat twee jaar geleden voor het laatst deed bij het vak Datastructuren. In python werkt het gelukkig haast hetzelfde als in java.\n",
    "* De functie add_term() ziet er erg bruut uit. Dit is voornamelijk omdat een deel van de code twee keer in het algoritme staat. Er moet namelijk rekening worden gehouden met of het DAGnode element al bestaat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
